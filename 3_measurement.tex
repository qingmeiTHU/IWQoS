\section{video quality issues on broadcaster side}

In this section, we measure on several popular personalized live streaming platforms and show the broadcaster-side quality degradation issue. We then analyze the root causes behind these issues, and propose possible methodologies of the solution.

\subsection{Measuring Broadcaster Performance}
\input{fig/setup.tex}
\textbf{Experiment setup.} We set up a live video streaming framework as in Figure~\ref{fig:setup}. Two servers (broadcaster and audience) both have 2 CPU cores and 6GB memory, and are equipped with $100$Mbps NICs; they are connected by a switch in the middle.
The broadcaster server uses OBS studio\cite{OBS} (one of the most popular broadcast software using RTMP protocol) to send videos, and it also has a bandwidth control module to emulate the network bandwidth in wireless environments (using linux tc modules and dummynet\cite{dummynet}). The audience server is built on nginx-rtmp module to receive videos and uses VLC player to play the rtmp stream.

\input{fig/case_study.tex}
\textbf{Case study: bad performance in variable networks.} We control the network bandwidth according to an actual trace from a wireless network. The trace records the real-time network conditions where a user joins the www.amazon.com on a mobile device. We aggregate packets in the trace into 5-second bins and calculate the data amount in each slot. We then control the network bandwidth on the broadcaster-side according to the per-second profile and the average bandwidth is up to $3000$kps. Finally we stream video at a bitrate of $3000$kbps via OBS and capture actual video packet trace using tcpdump in the audience's side. And the result is shown in Figure~\ref{fig:case-throughput}.  The trace lasts for $320$s, which is such a long time that we break the trace into two parts.

In the experiment results, we have two observations. (1) In the Figure~\ref{fig:case-throughput-a}, the actual throughput follows the trace closely. However, at 50s, the network bandwidth falls below the bitrate and the situation lasts for 2 seconds, while the actual throughput degrades to almost zero from 50s to 58s. This is an abnormal behavior, as \textit{a 2-second network jitter cascadingly causes 8-second throughput falling in the streaming application.} (2) A constant bitrate cannot efficiently handle long-term the bandwidth variance, which can be seen in Figure~\ref{fig:case-throughput-b}. Bandwidth is enough during $0-180s$, but the available bandwidth drops dramatically after 180s and the period lasts for $80s$, in which period massive frame drops occur\qm{done}. In this challenging network environment, the default OBS insists the previous bitrate and the strategy is obviously not satisfactory.

\input{fig/trace.tex}
\textbf{Prevalence of bad network conditions.} We study how often the bandwidth failure occurs by measuring the bandwidth distribution of two real-world datasets \textemdash\xspace FCC dataset~\cite{FCC_dataset} and HSDPA dataset~\cite{HSDPA_dataset}. Each trace lasts for 320s, and the combined dataset lasts for $30$ hours. For each trace, we normalize the trace by the average bandwidth and draw the CDF(Figure.~\ref{fig:trace}). Almost $50\%$ of traces are under the average throughput, which means for a $10$ second trace, about $5$ second the bandwidth is lower than the average. About $20\%$ of the traces are at most half of the average. The figure indicates that in real-world networks, bandwidth fluctuation frequently occurs. To further explain how often long-term bandwidth fluctuation happens, we draw a picture of network failure time distribution, as shown in figure~\ref{fig:trace-down}. Network failure time is calculated by counting the continuing time lower than the average bandwidth. About $20\%$ of the bandwidth fluctuation lasts for more than $10$ seconds, and some even lasts for hundreds of seconds. Keeping constant bitrate may introduce massive frame dropping. FCC dataset and HSDPA performs similar with the combined dataset, as we can see in the previous figures.

\input{fig/commercial.tex}
\textbf{Experiments on several commercial platforms.} We further repeat the experiment on different commercial platforms and settings to find whether the same issues exist.  Specifically, we test three different situations, including OBS pushing video to Douyu server, Douyu broadcaster to Douyu server, and OBS to twitch server. In the three experiments, the bitrate is chosen lower than the average bandwidth, $1700$kbps. Tcpdump is used to record the real-time throughput. We aggregate the data size in each tick(0.1s) together and draw a picture.
Figure~\ref{fig:commerical-drop} show the throughput of the three experiments respectively, ~\ref{fig:commerical-drop} is the corresponding numbers of dropped frames. The first three lines in Table~\ref{tbl:drop} show the total frame drops during the experiment.

Comparing the results across different platforms, we observe that the ``cascading effect'' is prevalent, appearing on all platforms (e.g., the 30s in OBS to Douyu, the 32s in Douyu to Douyu, and 43s in OBS to Twitch). For these three time periods, the frame dropping keeps a high value. We also find out that the cascading effect is not related to the instantaneously available bandwidth. For example, in Figure~\ref{fig:obs-douyu}, a dramatic bandwidth drop at 30s causes the cascading frame drop; while in Figure~\ref{fig:douyu}, a slight bandwidth drop at 32s causes the frame drop. Another observation is that the length of the cascading drop is different on different platforms: more than $5$s in Douyu and 2-3s in Twitch. Finally, from figures, we observe that the broadcaster software somewhat cannot tolerate short-period throughput drop.

\wenfei{rewrite this paragraph.} We test the ability to handle long-term throughput drop in figure~\ref{fig:vary-bandwidth}\wenfei{change the title of this figure.}. In 180-250s, the bandwidth drops dramatically, and only OBS broadcaster to Douyu cannot make full use of throughput. Although others follows the bandwidth, frames are dropped constantly this period. And we watch the real-time bitrate and find that all the three video bitrate keeps identical during the experiment. The ending three lines in table~\ref{tbl:drop} record the number of frame dropping. These present commercial platforms cannot solve the frame dropping problem in the long-term throughput drop scenario.

\subsection{Analyzing the Root Cause}
\input{fig/drop.tex}
In case of bandwidth failure, frames are dropped at the buffers in the streaming software. There exists a queue to temporarily store video frames. A video frame generating thread captures images from the camera, encodes raw images into H.264 frames, and enqueues the H.264 frames. While a frame sending thread dequeues frames and send them to the network via TCP socket operations (e.g., \mywrite) ~\ref{fig_drop}.
If the network is in bad conditions, the frame sending thread would be blocked, and then the queue accumulates until a threshold, disabling the frame generating thread to enqueue frames and thus dropping them.

\input{fig/frame_order.tex}
\input{fig/obs_drop_algo.tex}
The ``cascading effect'' of frame drop in transient bandwidth failure is caused by the dependency between frames. In H.264, a piece of video is organized into groups of pictures (GOP). During the encoding, the first frame in each group is kept unchanged (I frame); a few P frames are generated by computing their delta with the preceding I or P frame; a B frame is computed based on its neighboring I and/or P frames. Figure~\ref{fig:frame-order} shows an example of a series of I, B, P frames. The frames are indexed by display order, but the encoding/decoding is in a different order according to the dependency. Due to the dependency, when a P frame in the middle of a GOP is dropped, all following P, B frames within the same group would not be able to decode. Thus, if a small interruption from the network causes frame drop in the beginning or middle of a group, it cascadingly causes the remaining frames in the same group not decodable (or simply dropped).

We studied OBS broadcaster software and listed its frame management algorithm (Algorithm~\ref{alg:obs-drop}). At first, the drop priority is set to false. When a new frame arrives at the queue, if it is I frame, it is enqueued (never dropped); otherwise, the timespan of the frames in the queue is computed (i.e., the difference of the display timestamps between the latest and the earliest frame). If the incoming frame is a P frame, and if the timespan is shorter than 0.9 second, the P frame is enqueued; but if the drop priority corresponding P frame is true, the P frame is dropped; and if timespan is larger than 0.9 second, all P and B frames (including the ones in the queue and incoming ones) within the buffer are dropped, all the drop priority are set to true. Similarly, if the incoming frame is a B frame, the threshold is 0.7 second, and the processing logic is the same with that of P frames.

Finally, in long-term bandwidth degradation, frame generation speed exceeds the instanteneous wireless bandwidth, and frames are dropped. If key frames are dropped, the cascading effect would further exacerbate the performance. The essential reason is that the video bitrate cannot be adjusted adaptively to the instanteneous bandwidth.

\iffalse

The broadcaster usually runs software from the platform provider to generate live video and upload it an RTMP server. We studied an existing commercial video streaming software OBS~\ref{XX}; it has a video frame generating thread and frame sending thread, which forms a typical consumer-producer model. The video frame generating thread capture raw images from the device camera and encoding them into video frames (e.g., H.264), and enqueue the generated frames into a queue. While the frame sending thread takes frames from the queue and calls TCP socket interface (\mywrite) to send frames into the network. If the network is in bad conditions, the sending thread is blocked by the \mywrite operation of TCP, and the queue accumulates until a threshold causing the frame generating thread to drop frames.


There exists three kinds of frames, 'I', 'P', 'B', in H.264 format. 'I' frames are independent, 'P' frames depend on previous 'I' or 'P' frames. 'B' frames depend on neighbouring 'I', or 'P' frames. Missing higher priority frames will lead to decoding error to lower priority frames.
Streamer usually maintains a shallow buffer, as the figure shows\ref{fig_drop}. Encoder pushes the encoded frames into the buffer, at the same time, the streamer popes the buffered frames into the TCP socket. Reading the source code of OBS, we find that the default strategy results in the quality issue. Default strategy goes like that, record the time length of buffered frames, if the time larger than a certain value $0.7s$, drop all the B frames in the buffer, and reject all the following B frames until a P frame arrive. If the buffer exceeds $0.9s$, drop all the P frames in the buffer and to come, and wait for the key I frame. Dropping one P frame means all the remaining P frames in the GOP is useless, and a GOP usually lasts for a few seconds(for example, default 9s in OBS). Dependency of different frames and dropping frames lead to such quality issue.

H.264 is the typical video encoding mechanism using in video streaming. To generate video in the format of H.264, raw frames are put into groups of pictures (GOP), and then H.264 frames are computed within each group. In each group, the first frame is kept as I frame without change; a few P frames are computed by computing their delta with the preceding I frame or P frame; a B frame is computed based on its neighboring I frame and/or P frames. In video streaming, the broadcaster can preconfigure several parameters, including frames per second (FPS), resolution (width and height), and bitrate. During the video compression from raw frames to H.264 frames, I, P, B frames are computed and filters may be used to keep the preconfigured bitrate. For example, if the bitrate is low and FPS and resolution are high in the configuration, then the video compression filter would generate ``big pixels'' to reduce the bitrate, which actually reduce the video quality.

Combining the I, P, B frame in H.264 and the queue management in OBS, we present its frame dropping strategy. The frame sending thread always tries its best to dequeue and send frames. In the frame generating thread, I frames are always enqueued without dropping; for an incoming P frame, if the most recent frame in the queue is 0.9 second later than the most recent frame, the current P frame and existing P frames in the queue is dropped, and otherwise the P frame is enqueued; similarly for B frames, the threshold is 0.7 second.


Combining these two requirements, we find naive solutions is hard to guarantee both of them. To make the streaming resistant to bad network conditions such as low throughput and occasional jitters, the broadcast software tends to have larger buffer/queue to hold frames when the network cannot send them; while larger buffer would cause larger queuing delay, which hampers the requirement of low latency. Thus, we believe it is unique and challenging to achieve low-latency user-generated live video streaming that is resistant to unstable

\fi

\iffalse
\subsection{Commercial Applications}
To validate whether the commercial service provider has solved the issue, we repeat the same black box experiment on two commercial platforms(Twitch, Douyu) and three streamer(OBS, Douyu Tools, XSplit) respectively.
\fi
